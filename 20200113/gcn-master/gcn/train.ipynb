{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from gcn.utils import *\n",
    "from gcn.models import GCN, MLP\n",
    "\n",
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('dataset', 'cora', 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')  # 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([[   0,    0],\n",
      "       [ 633,    0],\n",
      "       [1862,    0],\n",
      "       ...,\n",
      "       [1473, 2707],\n",
      "       [2706, 2707],\n",
      "       [2707, 2707]], dtype=int32), array([0.25     , 0.25     , 0.2236068, ..., 0.2      , 0.2      ,\n",
      "       0.2      ]), (2708, 2708))]\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    print (support)\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0, 1274],\n",
       "        [   0, 1247],\n",
       "        [   0, 1194],\n",
       "        ...,\n",
       "        [2707,  329],\n",
       "        [2707,  186],\n",
       "        [2707,   19]], dtype=int32),\n",
       " array([0.11111111, 0.11111111, 0.11111111, ..., 0.07692308, 0.07692308,\n",
       "        0.07692308], dtype=float32),\n",
       " (2708, 1433))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/liouscott/anaconda3/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/metrics.py:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.95373 train_acc= 0.09286 val_loss= 1.95075 val_acc= 0.20200 time= 0.53712\n",
      "Epoch: 0002 train_loss= 1.94812 train_acc= 0.32857 val_loss= 1.94717 val_acc= 0.34000 time= 0.11068\n",
      "Epoch: 0003 train_loss= 1.94249 train_acc= 0.47857 val_loss= 1.94337 val_acc= 0.43000 time= 0.11135\n",
      "Epoch: 0004 train_loss= 1.93550 train_acc= 0.55000 val_loss= 1.93957 val_acc= 0.46400 time= 0.10956\n",
      "Epoch: 0005 train_loss= 1.92617 train_acc= 0.67143 val_loss= 1.93558 val_acc= 0.45400 time= 0.10993\n",
      "Epoch: 0006 train_loss= 1.91827 train_acc= 0.65714 val_loss= 1.93151 val_acc= 0.45400 time= 0.11056\n",
      "Epoch: 0007 train_loss= 1.90944 train_acc= 0.65714 val_loss= 1.92749 val_acc= 0.45600 time= 0.10662\n",
      "Epoch: 0008 train_loss= 1.90143 train_acc= 0.65714 val_loss= 1.92358 val_acc= 0.45400 time= 0.10780\n",
      "Epoch: 0009 train_loss= 1.89255 train_acc= 0.70000 val_loss= 1.91966 val_acc= 0.46600 time= 0.10790\n",
      "Epoch: 0010 train_loss= 1.88016 train_acc= 0.70000 val_loss= 1.91560 val_acc= 0.48200 time= 0.11098\n",
      "Epoch: 0011 train_loss= 1.87697 train_acc= 0.65714 val_loss= 1.91135 val_acc= 0.50000 time= 0.11026\n",
      "Epoch: 0012 train_loss= 1.87126 train_acc= 0.69286 val_loss= 1.90700 val_acc= 0.52800 time= 0.10886\n",
      "Epoch: 0013 train_loss= 1.85771 train_acc= 0.70000 val_loss= 1.90271 val_acc= 0.54600 time= 0.10878\n",
      "Epoch: 0014 train_loss= 1.84347 train_acc= 0.75000 val_loss= 1.89823 val_acc= 0.55600 time= 0.11463\n",
      "Epoch: 0015 train_loss= 1.83063 train_acc= 0.72857 val_loss= 1.89367 val_acc= 0.57200 time= 0.11248\n",
      "Epoch: 0016 train_loss= 1.81857 train_acc= 0.77143 val_loss= 1.88896 val_acc= 0.57600 time= 0.11341\n",
      "Epoch: 0017 train_loss= 1.81084 train_acc= 0.75714 val_loss= 1.88415 val_acc= 0.58800 time= 0.11348\n",
      "Epoch: 0018 train_loss= 1.79602 train_acc= 0.76429 val_loss= 1.87915 val_acc= 0.59200 time= 0.11698\n",
      "Epoch: 0019 train_loss= 1.77684 train_acc= 0.77857 val_loss= 1.87399 val_acc= 0.59600 time= 0.12116\n",
      "Epoch: 0020 train_loss= 1.77119 train_acc= 0.82857 val_loss= 1.86867 val_acc= 0.59800 time= 0.11731\n",
      "Epoch: 0021 train_loss= 1.76096 train_acc= 0.79286 val_loss= 1.86322 val_acc= 0.60000 time= 0.11774\n",
      "Epoch: 0022 train_loss= 1.75191 train_acc= 0.80000 val_loss= 1.85770 val_acc= 0.60400 time= 0.11540\n",
      "Epoch: 0023 train_loss= 1.72667 train_acc= 0.78571 val_loss= 1.85201 val_acc= 0.61200 time= 0.12032\n",
      "Epoch: 0024 train_loss= 1.72883 train_acc= 0.81429 val_loss= 1.84614 val_acc= 0.61600 time= 0.12052\n",
      "Epoch: 0025 train_loss= 1.71896 train_acc= 0.77143 val_loss= 1.84003 val_acc= 0.62200 time= 0.11784\n",
      "Epoch: 0026 train_loss= 1.69864 train_acc= 0.77143 val_loss= 1.83377 val_acc= 0.62400 time= 0.12490\n",
      "Epoch: 0027 train_loss= 1.69008 train_acc= 0.77143 val_loss= 1.82723 val_acc= 0.64000 time= 0.11616\n",
      "Epoch: 0028 train_loss= 1.68115 train_acc= 0.80714 val_loss= 1.82046 val_acc= 0.64400 time= 0.11827\n",
      "Epoch: 0029 train_loss= 1.64739 train_acc= 0.87143 val_loss= 1.81343 val_acc= 0.65000 time= 0.11884\n",
      "Epoch: 0030 train_loss= 1.64981 train_acc= 0.80714 val_loss= 1.80629 val_acc= 0.65800 time= 0.11594\n",
      "Epoch: 0031 train_loss= 1.61911 train_acc= 0.82857 val_loss= 1.79895 val_acc= 0.66600 time= 0.11260\n",
      "Epoch: 0032 train_loss= 1.61094 train_acc= 0.85714 val_loss= 1.79132 val_acc= 0.67000 time= 0.11474\n",
      "Epoch: 0033 train_loss= 1.59433 train_acc= 0.85000 val_loss= 1.78366 val_acc= 0.67600 time= 0.11411\n",
      "Epoch: 0034 train_loss= 1.59700 train_acc= 0.83571 val_loss= 1.77611 val_acc= 0.67800 time= 0.11096\n",
      "Epoch: 0035 train_loss= 1.54252 train_acc= 0.88571 val_loss= 1.76833 val_acc= 0.68200 time= 0.12458\n",
      "Epoch: 0036 train_loss= 1.56398 train_acc= 0.85000 val_loss= 1.76040 val_acc= 0.69000 time= 0.12220\n",
      "Epoch: 0037 train_loss= 1.54257 train_acc= 0.84286 val_loss= 1.75245 val_acc= 0.69400 time= 0.11700\n",
      "Epoch: 0038 train_loss= 1.51982 train_acc= 0.82857 val_loss= 1.74413 val_acc= 0.70400 time= 0.11707\n",
      "Epoch: 0039 train_loss= 1.51849 train_acc= 0.86429 val_loss= 1.73567 val_acc= 0.70800 time= 0.11241\n",
      "Epoch: 0040 train_loss= 1.48080 train_acc= 0.86429 val_loss= 1.72712 val_acc= 0.70600 time= 0.10803\n",
      "Epoch: 0041 train_loss= 1.47265 train_acc= 0.85000 val_loss= 1.71852 val_acc= 0.70800 time= 0.11248\n",
      "Epoch: 0042 train_loss= 1.49187 train_acc= 0.86429 val_loss= 1.70985 val_acc= 0.71400 time= 0.12108\n",
      "Epoch: 0043 train_loss= 1.42720 train_acc= 0.85000 val_loss= 1.70123 val_acc= 0.72000 time= 0.11978\n",
      "Epoch: 0044 train_loss= 1.43506 train_acc= 0.85000 val_loss= 1.69254 val_acc= 0.72600 time= 0.11747\n",
      "Epoch: 0045 train_loss= 1.43287 train_acc= 0.85714 val_loss= 1.68380 val_acc= 0.72400 time= 0.12120\n",
      "Epoch: 0046 train_loss= 1.39647 train_acc= 0.85000 val_loss= 1.67474 val_acc= 0.72800 time= 0.12559\n",
      "Epoch: 0047 train_loss= 1.37975 train_acc= 0.87143 val_loss= 1.66578 val_acc= 0.73000 time= 0.14245\n",
      "Epoch: 0048 train_loss= 1.37266 train_acc= 0.87857 val_loss= 1.65688 val_acc= 0.73400 time= 0.11754\n",
      "Epoch: 0049 train_loss= 1.37972 train_acc= 0.86429 val_loss= 1.64788 val_acc= 0.73600 time= 0.12537\n",
      "Epoch: 0050 train_loss= 1.34606 train_acc= 0.87143 val_loss= 1.63888 val_acc= 0.74200 time= 0.12260\n",
      "Epoch: 0051 train_loss= 1.33371 train_acc= 0.85714 val_loss= 1.62988 val_acc= 0.74200 time= 0.11749\n",
      "Epoch: 0052 train_loss= 1.37592 train_acc= 0.84286 val_loss= 1.62107 val_acc= 0.74400 time= 0.12267\n",
      "Epoch: 0053 train_loss= 1.29976 train_acc= 0.91429 val_loss= 1.61190 val_acc= 0.74600 time= 0.11553\n",
      "Epoch: 0054 train_loss= 1.28239 train_acc= 0.87857 val_loss= 1.60275 val_acc= 0.75400 time= 0.11768\n",
      "Epoch: 0055 train_loss= 1.28025 train_acc= 0.91429 val_loss= 1.59380 val_acc= 0.75800 time= 0.12130\n",
      "Epoch: 0056 train_loss= 1.23346 train_acc= 0.88571 val_loss= 1.58477 val_acc= 0.76200 time= 0.11734\n",
      "Epoch: 0057 train_loss= 1.25270 train_acc= 0.90000 val_loss= 1.57587 val_acc= 0.76400 time= 0.11041\n",
      "Epoch: 0058 train_loss= 1.21232 train_acc= 0.92857 val_loss= 1.56664 val_acc= 0.76800 time= 0.10922\n",
      "Epoch: 0059 train_loss= 1.24300 train_acc= 0.91429 val_loss= 1.55738 val_acc= 0.76800 time= 0.11431\n",
      "Epoch: 0060 train_loss= 1.22105 train_acc= 0.91429 val_loss= 1.54817 val_acc= 0.76800 time= 0.11565\n",
      "Epoch: 0061 train_loss= 1.20168 train_acc= 0.90714 val_loss= 1.53940 val_acc= 0.76800 time= 0.12193\n",
      "Epoch: 0062 train_loss= 1.18822 train_acc= 0.91429 val_loss= 1.53074 val_acc= 0.76800 time= 0.11650\n",
      "Epoch: 0063 train_loss= 1.17174 train_acc= 0.88571 val_loss= 1.52197 val_acc= 0.77000 time= 0.11151\n",
      "Epoch: 0064 train_loss= 1.19916 train_acc= 0.87143 val_loss= 1.51318 val_acc= 0.77000 time= 0.11932\n",
      "Epoch: 0065 train_loss= 1.12766 train_acc= 0.90714 val_loss= 1.50428 val_acc= 0.76800 time= 0.11977\n",
      "Epoch: 0066 train_loss= 1.11986 train_acc= 0.92857 val_loss= 1.49507 val_acc= 0.77600 time= 0.11967\n",
      "Epoch: 0067 train_loss= 1.14863 train_acc= 0.86429 val_loss= 1.48625 val_acc= 0.78000 time= 0.11523\n",
      "Epoch: 0068 train_loss= 1.09683 train_acc= 0.90714 val_loss= 1.47790 val_acc= 0.78000 time= 0.11315\n",
      "Epoch: 0069 train_loss= 1.07072 train_acc= 0.92143 val_loss= 1.46958 val_acc= 0.78000 time= 0.11325\n",
      "Epoch: 0070 train_loss= 1.12547 train_acc= 0.92143 val_loss= 1.46148 val_acc= 0.78000 time= 0.11099\n",
      "Epoch: 0071 train_loss= 1.09437 train_acc= 0.93571 val_loss= 1.45362 val_acc= 0.78000 time= 0.11079\n",
      "Epoch: 0072 train_loss= 1.03482 train_acc= 0.92857 val_loss= 1.44596 val_acc= 0.78000 time= 0.11244\n",
      "Epoch: 0073 train_loss= 1.05598 train_acc= 0.92143 val_loss= 1.43855 val_acc= 0.78200 time= 0.10995\n",
      "Epoch: 0074 train_loss= 1.11026 train_acc= 0.93571 val_loss= 1.43097 val_acc= 0.77800 time= 0.11204\n",
      "Epoch: 0075 train_loss= 1.04242 train_acc= 0.90714 val_loss= 1.42361 val_acc= 0.77800 time= 0.12472\n",
      "Epoch: 0076 train_loss= 1.06375 train_acc= 0.91429 val_loss= 1.41616 val_acc= 0.77800 time= 0.13359\n",
      "Epoch: 0077 train_loss= 0.97804 train_acc= 0.94286 val_loss= 1.40864 val_acc= 0.77800 time= 0.14103\n",
      "Epoch: 0078 train_loss= 1.02091 train_acc= 0.92857 val_loss= 1.40155 val_acc= 0.77800 time= 0.12913\n",
      "Epoch: 0079 train_loss= 0.99042 train_acc= 0.92857 val_loss= 1.39492 val_acc= 0.77800 time= 0.12474\n",
      "Epoch: 0080 train_loss= 0.97288 train_acc= 0.95000 val_loss= 1.38856 val_acc= 0.78000 time= 0.12301\n",
      "Epoch: 0081 train_loss= 0.98811 train_acc= 0.92143 val_loss= 1.38253 val_acc= 0.78000 time= 0.11087\n",
      "Epoch: 0082 train_loss= 0.97666 train_acc= 0.92857 val_loss= 1.37658 val_acc= 0.78000 time= 0.10828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0083 train_loss= 0.97041 train_acc= 0.90000 val_loss= 1.37076 val_acc= 0.78000 time= 0.10939\n",
      "Epoch: 0084 train_loss= 1.01846 train_acc= 0.93571 val_loss= 1.36531 val_acc= 0.78000 time= 0.11585\n",
      "Epoch: 0085 train_loss= 0.99078 train_acc= 0.90000 val_loss= 1.35981 val_acc= 0.78000 time= 0.11754\n",
      "Epoch: 0086 train_loss= 0.95950 train_acc= 0.95000 val_loss= 1.35422 val_acc= 0.78000 time= 0.12747\n",
      "Epoch: 0087 train_loss= 0.98173 train_acc= 0.94286 val_loss= 1.34867 val_acc= 0.78000 time= 0.13487\n",
      "Epoch: 0088 train_loss= 0.94133 train_acc= 0.95000 val_loss= 1.34307 val_acc= 0.78000 time= 0.13006\n",
      "Epoch: 0089 train_loss= 0.94469 train_acc= 0.91429 val_loss= 1.33738 val_acc= 0.77800 time= 0.14461\n",
      "Epoch: 0090 train_loss= 0.93210 train_acc= 0.90714 val_loss= 1.33178 val_acc= 0.77800 time= 0.12580\n",
      "Epoch: 0091 train_loss= 0.94818 train_acc= 0.94286 val_loss= 1.32622 val_acc= 0.77800 time= 0.13268\n",
      "Epoch: 0092 train_loss= 0.96379 train_acc= 0.93571 val_loss= 1.32098 val_acc= 0.77800 time= 0.12030\n",
      "Epoch: 0093 train_loss= 0.92452 train_acc= 0.92143 val_loss= 1.31627 val_acc= 0.77800 time= 0.12058\n",
      "Epoch: 0094 train_loss= 0.85478 train_acc= 0.95714 val_loss= 1.31182 val_acc= 0.77800 time= 0.11588\n",
      "Epoch: 0095 train_loss= 0.91923 train_acc= 0.92143 val_loss= 1.30745 val_acc= 0.77600 time= 0.11760\n",
      "Epoch: 0096 train_loss= 0.85466 train_acc= 0.96429 val_loss= 1.30330 val_acc= 0.77600 time= 0.14162\n",
      "Epoch: 0097 train_loss= 0.87474 train_acc= 0.92857 val_loss= 1.29896 val_acc= 0.77400 time= 0.11485\n",
      "Epoch: 0098 train_loss= 0.90325 train_acc= 0.92143 val_loss= 1.29444 val_acc= 0.77400 time= 0.11427\n",
      "Epoch: 0099 train_loss= 0.84998 train_acc= 0.94286 val_loss= 1.28940 val_acc= 0.77600 time= 0.11336\n",
      "Epoch: 0100 train_loss= 0.89317 train_acc= 0.95000 val_loss= 1.28432 val_acc= 0.77600 time= 0.11862\n",
      "Epoch: 0101 train_loss= 0.85654 train_acc= 0.95000 val_loss= 1.27931 val_acc= 0.77600 time= 0.11521\n",
      "Epoch: 0102 train_loss= 0.83025 train_acc= 0.95000 val_loss= 1.27413 val_acc= 0.77800 time= 0.13505\n",
      "Epoch: 0103 train_loss= 0.90886 train_acc= 0.92143 val_loss= 1.26932 val_acc= 0.77800 time= 0.12760\n",
      "Epoch: 0104 train_loss= 0.85497 train_acc= 0.95000 val_loss= 1.26467 val_acc= 0.78200 time= 0.11928\n",
      "Epoch: 0105 train_loss= 0.85640 train_acc= 0.92857 val_loss= 1.26004 val_acc= 0.78200 time= 0.11576\n",
      "Epoch: 0106 train_loss= 0.82504 train_acc= 0.97143 val_loss= 1.25542 val_acc= 0.78200 time= 0.11975\n",
      "Epoch: 0107 train_loss= 0.80829 train_acc= 0.92857 val_loss= 1.25126 val_acc= 0.78000 time= 0.12414\n",
      "Epoch: 0108 train_loss= 0.85372 train_acc= 0.94286 val_loss= 1.24752 val_acc= 0.78000 time= 0.12179\n",
      "Epoch: 0109 train_loss= 0.81557 train_acc= 0.92143 val_loss= 1.24411 val_acc= 0.78000 time= 0.12000\n",
      "Epoch: 0110 train_loss= 0.76667 train_acc= 0.96429 val_loss= 1.24009 val_acc= 0.78200 time= 0.11744\n",
      "Epoch: 0111 train_loss= 0.84375 train_acc= 0.93571 val_loss= 1.23637 val_acc= 0.78000 time= 0.12463\n",
      "Epoch: 0112 train_loss= 0.84792 train_acc= 0.95000 val_loss= 1.23268 val_acc= 0.77600 time= 0.11257\n",
      "Epoch: 0113 train_loss= 0.79518 train_acc= 0.96429 val_loss= 1.22935 val_acc= 0.77800 time= 0.12626\n",
      "Epoch: 0114 train_loss= 0.81337 train_acc= 0.95714 val_loss= 1.22661 val_acc= 0.78000 time= 0.11750\n",
      "Epoch: 0115 train_loss= 0.82696 train_acc= 0.97143 val_loss= 1.22360 val_acc= 0.77800 time= 0.11872\n",
      "Epoch: 0116 train_loss= 0.80620 train_acc= 0.91429 val_loss= 1.22019 val_acc= 0.78000 time= 0.12361\n",
      "Epoch: 0117 train_loss= 0.82210 train_acc= 0.95000 val_loss= 1.21697 val_acc= 0.78200 time= 0.11857\n",
      "Epoch: 0118 train_loss= 0.78598 train_acc= 0.95000 val_loss= 1.21387 val_acc= 0.78200 time= 0.11522\n",
      "Epoch: 0119 train_loss= 0.80300 train_acc= 0.95000 val_loss= 1.21076 val_acc= 0.78200 time= 0.11366\n",
      "Epoch: 0120 train_loss= 0.76708 train_acc= 0.97143 val_loss= 1.20728 val_acc= 0.78400 time= 0.11730\n",
      "Epoch: 0121 train_loss= 0.80297 train_acc= 0.94286 val_loss= 1.20400 val_acc= 0.78400 time= 0.12291\n",
      "Epoch: 0122 train_loss= 0.75991 train_acc= 0.95000 val_loss= 1.20050 val_acc= 0.78400 time= 0.11543\n",
      "Epoch: 0123 train_loss= 0.76395 train_acc= 0.95714 val_loss= 1.19687 val_acc= 0.78400 time= 0.11887\n",
      "Epoch: 0124 train_loss= 0.77066 train_acc= 0.95714 val_loss= 1.19322 val_acc= 0.78400 time= 0.11822\n",
      "Epoch: 0125 train_loss= 0.76932 train_acc= 0.95714 val_loss= 1.18932 val_acc= 0.78400 time= 0.11422\n",
      "Epoch: 0126 train_loss= 0.75021 train_acc= 0.94286 val_loss= 1.18547 val_acc= 0.78400 time= 0.11371\n",
      "Epoch: 0127 train_loss= 0.76891 train_acc= 0.92143 val_loss= 1.18196 val_acc= 0.78200 time= 0.11896\n",
      "Epoch: 0128 train_loss= 0.72375 train_acc= 0.97857 val_loss= 1.17854 val_acc= 0.78400 time= 0.11192\n",
      "Epoch: 0129 train_loss= 0.74320 train_acc= 0.93571 val_loss= 1.17509 val_acc= 0.78200 time= 0.11926\n",
      "Epoch: 0130 train_loss= 0.79010 train_acc= 0.92857 val_loss= 1.17201 val_acc= 0.78200 time= 0.11681\n",
      "Epoch: 0131 train_loss= 0.75802 train_acc= 0.95714 val_loss= 1.16900 val_acc= 0.78200 time= 0.11382\n",
      "Epoch: 0132 train_loss= 0.76183 train_acc= 0.97143 val_loss= 1.16582 val_acc= 0.78200 time= 0.11822\n",
      "Epoch: 0133 train_loss= 0.68512 train_acc= 0.95714 val_loss= 1.16298 val_acc= 0.78000 time= 0.11899\n",
      "Epoch: 0134 train_loss= 0.74747 train_acc= 0.95714 val_loss= 1.16028 val_acc= 0.78000 time= 0.12771\n",
      "Epoch: 0135 train_loss= 0.68341 train_acc= 0.97143 val_loss= 1.15789 val_acc= 0.78000 time= 0.12084\n",
      "Epoch: 0136 train_loss= 0.71162 train_acc= 0.96429 val_loss= 1.15595 val_acc= 0.78000 time= 0.13111\n",
      "Epoch: 0137 train_loss= 0.76564 train_acc= 0.96429 val_loss= 1.15415 val_acc= 0.78000 time= 0.12577\n",
      "Epoch: 0138 train_loss= 0.71910 train_acc= 0.96429 val_loss= 1.15209 val_acc= 0.78200 time= 0.12580\n",
      "Epoch: 0139 train_loss= 0.76463 train_acc= 0.94286 val_loss= 1.15014 val_acc= 0.78200 time= 0.11279\n",
      "Epoch: 0140 train_loss= 0.69996 train_acc= 0.95714 val_loss= 1.14854 val_acc= 0.78400 time= 0.11612\n",
      "Epoch: 0141 train_loss= 0.72332 train_acc= 0.95714 val_loss= 1.14792 val_acc= 0.78400 time= 0.11606\n",
      "Epoch: 0142 train_loss= 0.72512 train_acc= 0.96429 val_loss= 1.14742 val_acc= 0.78400 time= 0.11712\n",
      "Epoch: 0143 train_loss= 0.68661 train_acc= 0.95000 val_loss= 1.14660 val_acc= 0.78200 time= 0.12048\n",
      "Epoch: 0144 train_loss= 0.74463 train_acc= 0.93571 val_loss= 1.14545 val_acc= 0.78200 time= 0.11674\n",
      "Epoch: 0145 train_loss= 0.68075 train_acc= 0.96429 val_loss= 1.14403 val_acc= 0.78000 time= 0.11116\n",
      "Epoch: 0146 train_loss= 0.70026 train_acc= 0.96429 val_loss= 1.14251 val_acc= 0.78400 time= 0.12258\n",
      "Epoch: 0147 train_loss= 0.68024 train_acc= 0.93571 val_loss= 1.14075 val_acc= 0.78200 time= 0.11346\n",
      "Epoch: 0148 train_loss= 0.70145 train_acc= 0.96429 val_loss= 1.13866 val_acc= 0.78400 time= 0.11475\n",
      "Epoch: 0149 train_loss= 0.67701 train_acc= 0.96429 val_loss= 1.13657 val_acc= 0.78200 time= 0.11813\n",
      "Epoch: 0150 train_loss= 0.68453 train_acc= 0.94286 val_loss= 1.13420 val_acc= 0.78200 time= 0.12061\n",
      "Epoch: 0151 train_loss= 0.66527 train_acc= 0.98571 val_loss= 1.13140 val_acc= 0.78400 time= 0.11511\n",
      "Epoch: 0152 train_loss= 0.67694 train_acc= 0.96429 val_loss= 1.12885 val_acc= 0.78400 time= 0.11656\n",
      "Epoch: 0153 train_loss= 0.71368 train_acc= 0.94286 val_loss= 1.12607 val_acc= 0.78400 time= 0.11399\n",
      "Epoch: 0154 train_loss= 0.68269 train_acc= 0.93571 val_loss= 1.12300 val_acc= 0.78400 time= 0.11252\n",
      "Epoch: 0155 train_loss= 0.66479 train_acc= 0.97857 val_loss= 1.12022 val_acc= 0.78400 time= 0.11685\n",
      "Epoch: 0156 train_loss= 0.69107 train_acc= 0.96429 val_loss= 1.11803 val_acc= 0.78400 time= 0.11497\n",
      "Epoch: 0157 train_loss= 0.63052 train_acc= 0.97857 val_loss= 1.11589 val_acc= 0.78200 time= 0.11139\n",
      "Epoch: 0158 train_loss= 0.67463 train_acc= 0.96429 val_loss= 1.11338 val_acc= 0.78200 time= 0.10658\n",
      "Epoch: 0159 train_loss= 0.66616 train_acc= 0.94286 val_loss= 1.11111 val_acc= 0.78000 time= 0.11026\n",
      "Epoch: 0160 train_loss= 0.66629 train_acc= 0.95714 val_loss= 1.10851 val_acc= 0.78000 time= 0.11701\n",
      "Epoch: 0161 train_loss= 0.67079 train_acc= 0.97857 val_loss= 1.10609 val_acc= 0.78200 time= 0.11369\n",
      "Epoch: 0162 train_loss= 0.69043 train_acc= 0.97857 val_loss= 1.10330 val_acc= 0.78200 time= 0.11738\n",
      "Epoch: 0163 train_loss= 0.67199 train_acc= 0.95000 val_loss= 1.10098 val_acc= 0.78200 time= 0.11033\n",
      "Epoch: 0164 train_loss= 0.65285 train_acc= 0.95714 val_loss= 1.09904 val_acc= 0.78200 time= 0.10977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0165 train_loss= 0.71285 train_acc= 0.95000 val_loss= 1.09738 val_acc= 0.78000 time= 0.11122\n",
      "Epoch: 0166 train_loss= 0.66846 train_acc= 0.95000 val_loss= 1.09619 val_acc= 0.78000 time= 0.11391\n",
      "Epoch: 0167 train_loss= 0.65185 train_acc= 0.97143 val_loss= 1.09502 val_acc= 0.78000 time= 0.11717\n",
      "Epoch: 0168 train_loss= 0.65922 train_acc= 0.95000 val_loss= 1.09437 val_acc= 0.78000 time= 0.10786\n",
      "Epoch: 0169 train_loss= 0.63922 train_acc= 0.98571 val_loss= 1.09393 val_acc= 0.78000 time= 0.11038\n",
      "Epoch: 0170 train_loss= 0.65303 train_acc= 0.95000 val_loss= 1.09337 val_acc= 0.78400 time= 0.10880\n",
      "Epoch: 0171 train_loss= 0.71675 train_acc= 0.95000 val_loss= 1.09231 val_acc= 0.78400 time= 0.11562\n",
      "Epoch: 0172 train_loss= 0.60315 train_acc= 0.96429 val_loss= 1.09168 val_acc= 0.78400 time= 0.11160\n",
      "Epoch: 0173 train_loss= 0.66708 train_acc= 0.95000 val_loss= 1.09123 val_acc= 0.78200 time= 0.11154\n",
      "Epoch: 0174 train_loss= 0.60544 train_acc= 0.96429 val_loss= 1.09062 val_acc= 0.78400 time= 0.11149\n",
      "Epoch: 0175 train_loss= 0.62438 train_acc= 0.95714 val_loss= 1.08964 val_acc= 0.78200 time= 0.10957\n",
      "Epoch: 0176 train_loss= 0.62084 train_acc= 0.97857 val_loss= 1.08855 val_acc= 0.78400 time= 0.10850\n",
      "Epoch: 0177 train_loss= 0.66996 train_acc= 0.96429 val_loss= 1.08688 val_acc= 0.78400 time= 0.10677\n",
      "Epoch: 0178 train_loss= 0.60861 train_acc= 0.95714 val_loss= 1.08472 val_acc= 0.78600 time= 0.11841\n",
      "Epoch: 0179 train_loss= 0.67340 train_acc= 0.93571 val_loss= 1.08298 val_acc= 0.78600 time= 0.10835\n",
      "Epoch: 0180 train_loss= 0.66175 train_acc= 0.95000 val_loss= 1.08165 val_acc= 0.78600 time= 0.10743\n",
      "Epoch: 0181 train_loss= 0.61844 train_acc= 0.97143 val_loss= 1.07973 val_acc= 0.78800 time= 0.10815\n",
      "Epoch: 0182 train_loss= 0.63747 train_acc= 0.95000 val_loss= 1.07774 val_acc= 0.78800 time= 0.11162\n",
      "Epoch: 0183 train_loss= 0.65082 train_acc= 0.96429 val_loss= 1.07553 val_acc= 0.79000 time= 0.11220\n",
      "Epoch: 0184 train_loss= 0.64940 train_acc= 0.96429 val_loss= 1.07379 val_acc= 0.79000 time= 0.10855\n",
      "Epoch: 0185 train_loss= 0.65327 train_acc= 0.96429 val_loss= 1.07198 val_acc= 0.79000 time= 0.10956\n",
      "Epoch: 0186 train_loss= 0.64274 train_acc= 0.93571 val_loss= 1.07061 val_acc= 0.78800 time= 0.10787\n",
      "Epoch: 0187 train_loss= 0.61765 train_acc= 0.95714 val_loss= 1.06936 val_acc= 0.78600 time= 0.10757\n",
      "Epoch: 0188 train_loss= 0.59455 train_acc= 0.95000 val_loss= 1.06786 val_acc= 0.78600 time= 0.11626\n",
      "Epoch: 0189 train_loss= 0.62280 train_acc= 0.96429 val_loss= 1.06605 val_acc= 0.78600 time= 0.10770\n",
      "Epoch: 0190 train_loss= 0.58775 train_acc= 0.96429 val_loss= 1.06476 val_acc= 0.78400 time= 0.11931\n",
      "Epoch: 0191 train_loss= 0.60825 train_acc= 0.96429 val_loss= 1.06330 val_acc= 0.78400 time= 0.10785\n",
      "Epoch: 0192 train_loss= 0.66347 train_acc= 0.95000 val_loss= 1.06135 val_acc= 0.78400 time= 0.10729\n",
      "Epoch: 0193 train_loss= 0.61228 train_acc= 0.95000 val_loss= 1.05893 val_acc= 0.78400 time= 0.10851\n",
      "Epoch: 0194 train_loss= 0.57785 train_acc= 0.96429 val_loss= 1.05669 val_acc= 0.78400 time= 0.10684\n",
      "Epoch: 0195 train_loss= 0.61476 train_acc= 0.95714 val_loss= 1.05407 val_acc= 0.78400 time= 0.10879\n",
      "Epoch: 0196 train_loss= 0.60326 train_acc= 0.97857 val_loss= 1.05155 val_acc= 0.78200 time= 0.11268\n",
      "Epoch: 0197 train_loss= 0.60377 train_acc= 0.97143 val_loss= 1.04940 val_acc= 0.78000 time= 0.11778\n",
      "Epoch: 0198 train_loss= 0.60680 train_acc= 0.95000 val_loss= 1.04847 val_acc= 0.78000 time= 0.11689\n",
      "Epoch: 0199 train_loss= 0.61920 train_acc= 0.96429 val_loss= 1.04797 val_acc= 0.78400 time= 0.11095\n",
      "Epoch: 0200 train_loss= 0.57948 train_acc= 0.96429 val_loss= 1.04753 val_acc= 0.78600 time= 0.11935\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    #print (feed_dict)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'Placeholder_5:0' shape=(?, 7) dtype=float32>: array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " <tf.Tensor 'Placeholder_6:0' shape=<unknown> dtype=int32>: array([ True,  True,  True, ..., False, False, False]),\n",
       " <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x10a2d1a90>: (array([[   0, 1274],\n",
       "         [   0, 1247],\n",
       "         [   0, 1194],\n",
       "         ...,\n",
       "         [2707,  329],\n",
       "         [2707,  186],\n",
       "         [2707,   19]], dtype=int32),\n",
       "  array([0.11111111, 0.11111111, 0.11111111, ..., 0.07692308, 0.07692308,\n",
       "         0.07692308], dtype=float32),\n",
       "  (2708, 1433)),\n",
       " <tensorflow.python.framework.sparse_tensor.SparseTensor at 0xd36aa0e10>: (array([[   0,    0],\n",
       "         [ 633,    0],\n",
       "         [1862,    0],\n",
       "         ...,\n",
       "         [1473, 2707],\n",
       "         [2706, 2707],\n",
       "         [2707, 2707]], dtype=int32),\n",
       "  array([0.25     , 0.25     , 0.2236068, ..., 0.2      , 0.2      ,\n",
       "         0.2      ]),\n",
       "  (2708, 2708)),\n",
       " <tf.Tensor 'Placeholder_7:0' shape=<unknown> dtype=int32>: (49216,),\n",
       " <tf.Tensor 'PlaceholderWithDefault:0' shape=() dtype=float32>: 0.5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 1.00983 accuracy= 0.81300 time= 0.05553\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
