{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import jieba,re\n",
    "import pandas as pd\n",
    "\n",
    "def imap_unordered_bar(func, args, n_processes=2):  # multi-processing function\n",
    "    \n",
    "    p = Pool(n_processes)\n",
    "    res_list = {}\n",
    "    with tqdm(total=1, dynamic_ncols=True) as pbar:\n",
    "        for i, res in tqdm(enumerate(p.imap_unordered(func, args)), disable=True):\n",
    "            pbar.update()\n",
    "            res_list.update(res)\n",
    "    pbar.close()\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    return res_list\n",
    "\n",
    "\n",
    "def stopwordslist(filepath):  # read stopwords\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def jieba_seg_parallel(data, stopwords, cid):  # jieba\n",
    "    import jieba\n",
    "    row = []\n",
    "    dic = {}\n",
    "   \n",
    "    seg_list = jieba.cut(data)\n",
    "\n",
    "    for w in seg_list:\n",
    "        if w not in stopwords:\n",
    "            row.append(w)\n",
    "    dic[cid] = row\n",
    "\n",
    "    return dic\n",
    "\n",
    "def all_run(content, stopword):\n",
    "    \n",
    "    global jieba\n",
    "    def jieba(self):\n",
    "        result = jieba_seg_parallel(self[0], stopword, self[1])\n",
    "        return result\n",
    "    \n",
    "    done_x = imap_unordered_bar(jieba, content, 1)\n",
    "    \n",
    "    return done_x\n",
    "\n",
    "def remove_punctuation(getdata):  # regular\n",
    "\n",
    "    rule = re.compile(\"[^a-zA-Z0-9\\u4e00-\\u9fa5]\")\n",
    "    line = rule.sub('', getdata)\n",
    "\n",
    "    return line\n",
    "\n",
    "\n",
    "def seg(df,to_jieba_data, stopwords,seg_type):  # add new colum jieba\n",
    "    word_dict = all_run(to_jieba_data, stopwords)  # to_jieba_data\n",
    "    keys = list(word_dict.keys())\n",
    "    values = list(word_dict.values())\n",
    "    jieba_df = pd.DataFrame(keys, columns=['id'])\n",
    "    jieba_df[seg_type] = values\n",
    "    get_df = pd.merge(df, jieba_df, on=['id'])\n",
    "    return get_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stopwords = stopwordslist('read your stop words')\n",
    "   \n",
    "    df_seg = seg(new_df,new_df[['your content','your content id']].values, stopwords,'seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "def imap_unordered_bar(func, args, n_processes = 2): # multi-processing function\n",
    "    p = Pool(n_processes)\n",
    "    res_list = []\n",
    "    with tqdm(total = 1, dynamic_ncols=True) as pbar:\n",
    "        for i, res in tqdm(enumerate(p.imap_unordered(func, args)), disable=True):\n",
    "            pbar.update()\n",
    "            res_list.append(res)\n",
    "    pbar.close()\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return res_list\n",
    "\n",
    "def dtw_parallel(self,pair):\n",
    "\n",
    "    distance, path = fastdtw(self[0],self[1] , dist=euclidean)\n",
    "    return [distance, pair[0],pair[1]]\n",
    "\n",
    "def all_run_dtw(pairdict, pair):\n",
    "\n",
    "    global cal_fun_input\n",
    "    def cal_fun_input(self):\n",
    "        data = pairdict[self] \n",
    "        result = dtw_parallel(data,self)\n",
    "        return result\n",
    "    \n",
    "    done_x = imap_unordered_bar(cal_fun_input, pair, 6)\n",
    "    return done_x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dist_list = all_run_dtw(pairdict, pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
