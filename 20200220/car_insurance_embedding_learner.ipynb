{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import preprocessing\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence\n",
    "TaggededDocument = gensim.models.doc2vec.TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cathay_embedding_lang_learners(object):\n",
    "    def __init__(self, embedding_size):\n",
    "        self.size=embedding_size\n",
    "        self.x_train = []\n",
    "        self.words2vec =[]    \n",
    "        self.seq_dict = {0:'a',1:'b',2:'c',3:'d',4:'e',5:'f',6:'g',7:'h',8:'i',9:'j',10:'k',11:'l',\n",
    "                    12:'m',13:'n',14:'o',15:'p',16:'q',17:'r',18:'s',19:'t',20:'u',21:'v',22:'w',23:'x',24:'y',25:'z'}\n",
    "        self.alpha_seq = []\n",
    "        self.slot_num = 26\n",
    "        self.arr = ''\n",
    "        \n",
    "    def norm_numerical_ts(self, data):\n",
    "        min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0.01, 0.99))\n",
    "\n",
    "        for i in data.columns:\n",
    "            if data[i].values[0] != '@':\n",
    "                x = data[i].values.reshape(-1, 1) \n",
    "                x_scaled = min_max_scaler.fit_transform(x)\n",
    "                data[i] = x_scaled\n",
    "        self.ts_data = data\n",
    "\n",
    "    def alphabetical_seq(self):     \n",
    "        \n",
    "        # Put array elements in different alphabet \n",
    "        for row in range(len(self.ts_data)):\n",
    "            for col in range(len(self.ts_data.columns)):\n",
    "                if self.ts_data.iloc[row,col] == '@':\n",
    "                    self.arr = self.arr + '@'\n",
    "                else:\n",
    "                    self.arr = self.arr + self.seq_dict[int(self.slot_num*self.ts_data.iloc[row,col])]\n",
    "            self.alpha_seq.append(self.arr)   \n",
    "            self.arr = ''\n",
    "\n",
    "    def remove_mark(self):\n",
    "        for i in range(len(self.alpha_seq)):\n",
    "            self.alpha_seq[i] = self.alpha_seq[i].replace('@',' ')\n",
    "\n",
    "    def words_to_vec(self):\n",
    "\n",
    "        for i,sub_list in enumerate(self.alpha_seq):\n",
    "            document = TaggededDocument(sub_list, tags=[i])\n",
    "            self.x_train.append(document)\n",
    "\n",
    "        model_dm = Doc2Vec(self.x_train, min_count=1, dm=1, dm_mean=1, window = 4, vector_size = self.size, sample=1e-3, negative=5, workers=4,hs=1,epochs=6)\n",
    "        model_dm.train(self.x_train, total_examples=model_dm.corpus_count, epochs=70)\n",
    "\n",
    "        for i in range(len(self.x_train)):\n",
    "            self.words2vec.append(model_dm.docvecs[i])\n",
    "        self.words2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ts_data = pd.read_csv('data/car_insurance_data1.csv', sep = ',', header=None)\n",
    "    #ts_data = pd.read_csv('data/'+sys.argv[1]+'.csv', sep = ',', header=None) # for .py\n",
    "    len_of_ref_seq = len(ts_data)\n",
    "    for i in range(1,145,4):\n",
    "        ts_data[i] = '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    embedding_size = 10\n",
    "    CELL = cathay_embedding_lang_learners(embedding_size)\n",
    "    CELL.norm_numerical_ts(ts_data) ### step 1, normalize a numerical series to a given range\n",
    "    CELL.alphabetical_seq()         ### step 2, transform the scaled numerical series to an alphabetical sequence\n",
    "    CELL.remove_mark()              ### step 3, split the letters to form a word\n",
    "    CELL.words_to_vec()             ### step 4, transform a word to a vector\n",
    "    result = pd.DataFrame(CELL.words2vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    result.to_csv(\"data/features_embedding_car_insurance_data1.csv\", index = None)\n",
    "    #result.to_csv(\"data/features_embedding_\"+sys.argv[1]+\".csv\", index = None) # for .py\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
